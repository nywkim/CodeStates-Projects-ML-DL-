{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_06_김영우_P4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1l4Jw9-IgyYo5pJ2yrtLVmJS0l4Hm71IB",
      "authorship_tag": "ABX9TyNtt5zKbZc8JHrIBLYdrHez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nywkim/project/blob/main/AI_06_%EA%B9%80%EC%98%81%EC%9A%B0_P4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YvBvyekjwzg"
      },
      "source": [
        "### Project 4\n",
        "## 간단한 음원 데이터 장르 분류 모델 만들기\n",
        "#### 대략적인 데이터 셋의 정보와 음원 데이터를 분석하는 데 알아야 할 지식들을 살펴보고, 전처리 이후 모델을 만들어 비교해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UeJXOa1MlFm"
      },
      "source": [
        "import librosa, IPython\n",
        "import librosa.display as lplt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "seed = 99\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60zNRuwNnqNK"
      },
      "source": [
        "# 오디오를 wav 파일로 변환 후 저장\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "dst = \"test.wav\"\n",
        "\n",
        "audSeg = AudioSegment.from_file('drive/MyDrive/Love&Evil.m4a')\n",
        "# mp3파일은 audSeg = AudioSegment.from_mp3(src)\n",
        "audSeg.export(dst, format=\"wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBHTec3Qox4g"
      },
      "source": [
        "# 오디오 부착\n",
        "import os\n",
        "wav = 'test.wav'\n",
        "(file_dir, file_id) = os.path.split(wav)\n",
        "print(\"file_id:\", file_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxYzg6lu4R52"
      },
      "source": [
        "import wave\n",
        "import array\n",
        "w = wave.open(os.path.join(os.getcwd(), \"test.wav\"), \"r\")\n",
        "\n",
        "print('음원의 프레임 수 :', w.getnframes())\n",
        "print('음원의 초당 프레임 수 :', w.getframerate())\n",
        "print('음원의 채널 수 :', w.getnchannels())\n",
        "\n",
        "wavLen = w.getnframes() / w.getframerate()\n",
        "# 길이 = 음원의 프레임 수 / 음원의 초당 프레임 수\n",
        "\n",
        "buffer = w.readframes(w.getnframes())\n",
        "# 해당 음원을 음원의 프레임 수만큼 프레임을 읽어 버퍼로 로드\n",
        "\n",
        "amplitude = (np.frombuffer(buffer, dtype=\"int16\"))\n",
        "# 로드한 버퍼를 int16형식의 데이터타입을 담은 리스트를 amplitude 변수에 담는다.\n",
        "# 진폭배열의 길이 = 프레임 수 * 채널 수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NMAcjUm439b"
      },
      "source": [
        "# 음원의 시작과 끝 시간 설정\n",
        "startsec = 3\n",
        "endsec = 33\n",
        "s_amp = amplitude[int(startsec * w.getframerate() * w.getnchannels()):int(endsec * w.getframerate() * w.getnchannels())]\n",
        "# \"시작 초 (=startsec) * 프레임 수 * 채널 수 ~ 끝 초 (=endsec) * 프레임 수 * 채널 수\"까지만 s_amp에 담기."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk0BVlbG5RVr"
      },
      "source": [
        "save_wave = wave.Wave_write(os.path.join(\"cut.wav\"))\n",
        "                    # 저장할 위치를 지정하는 함수.\n",
        "save_wave.setparams(w.getparams())\n",
        "                    # 파라미터를 설정하며, writeframes를 통해 프레임별로 들어갈 파형값을 배열에서 가져옴\n",
        "save_wave.writeframes(array.array('h', s_amp).tobytes())\n",
        "                    # array.array는 s_amp 리스트 안의 값을 제시되는 타입값으로 배열을 생성함.\n",
        "save_wave.close()   # 스트림 close\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1QYHMGN5kDy"
      },
      "source": [
        "##librosa를 통한 오디오 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcDxgQ7y8o4Y"
      },
      "source": [
        "audio = 'cut.wav'\n",
        "data, sr = librosa.load(audio) # 진폭을 시간 순서대로 나열한 것, Hz(1초당 샘플 단위)\n",
        "audio_data, _ = librosa.effects.trim(data) # 오디오 시각화를 위한 손질"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5Qfb7g8RCp"
      },
      "source": [
        "IPython.display.Audio(audio_data, rate=sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JzkLVcT854g"
      },
      "source": [
        "plt.figure(figsize=(15,5)) # 시각화 크기 설정\n",
        "lplt.waveplot(audio_data)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRozchglOk8J"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "librosa.display.waveplot(data, sr, alpha=0.5)\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Waveform\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnnMcQZrIH2G"
      },
      "source": [
        "# 푸리에 변환 : Time > Frequency, 진폭 > 크기 (분석을 위하여) 각 주파수가 얼마만큼의 크기를 차지하는지 나타냄.\n",
        "# fft sample\n",
        "fft = np.fft.fft(data)\n",
        "\n",
        "magnitude = np.abs(fft) \n",
        "\n",
        "f = np.linspace(0,sr,len(magnitude))\n",
        "\n",
        "left_spectrum = magnitude[:int(len(magnitude) / 2)]\n",
        "left_f = f[:int(len(magnitude) / 2)]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(left_f, left_spectrum)\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"Magnitude\")\n",
        "plt.title(\"Power spectrum\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoQUhEv2fc4I"
      },
      "source": [
        "# STFT는 음성을 일정 작은 프레임으로 잘라 시간순으로 붙여 푸리에 변환을 한 것.\n",
        "hop_length = 512\n",
        "n_fft = 2048\n",
        "\n",
        "Fourier = np.abs(librosa.stft(data, n_fft=n_fft, hop_length=hop_length))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(Fourier)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8URsgiInn1P"
      },
      "source": [
        "# Spectrogram : time과 frequency 사이 음의 세기를 dB로 변환하여 색으로 표현\n",
        "hop_length_duration = float(hop_length) / sr\n",
        "n_fft_duration = float(n_fft) / sr\n",
        "\n",
        "stft = librosa.stft(data, n_fft=n_fft, hop_length=hop_length)\n",
        "magnitude = np.abs(stft)\n",
        "log_spectrogram = librosa.amplitude_to_db(magnitude, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', hop_length=hop_length)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.title(\"Spectrogram (dB)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMq6FPOoWFqQ"
      },
      "source": [
        "\"\"\"\n",
        "Mel_spectrogram 만들기\n",
        "우리는 인접한 주파수와 높은 주파수 대역은 잘 구분하지 못하기 때문에,\n",
        "이런 인간의 청각적 지각 능력에 맞춰서 로그 스케일로 스펙트로그램의 주파수 축을 줄이고\n",
        "이 값들을 몇 개의 주파수 대역대로 묶으면 크기를 줄이는 동시에 가장 중요한 정보들을 보존할 수 있는 멜 스펙트로그램(mel-spectrogram)을 만들 수 있다,\n",
        "\"\"\"\n",
        "mel_spec = librosa.feature.melspectrogram(data, sr=sr)\n",
        "mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "lplt.specshow(mel_spec_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log')\n",
        "plt.colorbar()\n",
        "plt.title(\"Mel Spectrogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gf_cpfJjQ1j"
      },
      "source": [
        "# BPM 추출\n",
        "tempo, _ = librosa.beat.beat_track(data, sr=sr)\n",
        "print('BPM :', tempo)\n",
        "\n",
        "# Zero Crossing Rate (mean, var) 음파가 0 값을 지나치는 비율\n",
        "zero_c = librosa.zero_crossings(data, pad=False)\n",
        "zero_crossing_rate_mean = np.mean(zero_c)\n",
        "print('zero_crossing_rate_mean :', zero_crossing_rate_mean)\n",
        "zero_crossing_rate_var = np.var(zero_c)\n",
        "print('zero_crossing_rate_var :', zero_crossing_rate_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e-jU9eolWxN"
      },
      "source": [
        "# Harmonics(사람이 귀로 구분하기 힘든 음악의 특징들)\n",
        "# Percussives(리듬, 감정을 나타내는 충격파)\n",
        "harm, perc = librosa.effects.hpss(data)\n",
        "\n",
        "harmony_mean = np.mean(harm)\n",
        "harmony_var = np.var(harm)\n",
        "perceptr_mean = np.mean(perc)\n",
        "perceptr_var = np.var(perc)\n",
        "\n",
        "print('harmony (mean, var) & percussive (mean, var)')\n",
        "print(harmony_mean, harmony_var), print(perceptr_mean, perceptr_var)\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.plot(harm, color='g')\n",
        "plt.plot(perc, color='r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXxJd1KlpryI"
      },
      "source": [
        "# Spectral Centroid : 소리의 중심이 어디에 크게 실려있는지 확인.\n",
        "spec_centroids = librosa.feature.spectral_centroid(data, sr=sr)[0]\n",
        "spectral_centroid_mean = np.mean(spec_centroids)\n",
        "spectral_centroid_var = np.var(spec_centroids)\n",
        "\n",
        "frames = range(len(spec_centroids))\n",
        "t = librosa.frames_to_time(frames)\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "librosa.display.waveplot(data, sr=sr, alpha=0.5, color='b')\n",
        "plt.plot(t, preprocessing.minmax_scale(spec_centroids), color='r') # 0-1사이로 맞춰 디스플레이\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdke4U8S73g_"
      },
      "source": [
        "# Spectral Rolloff : 낮은 주파수에 어느 부분이 얼마나 집중되었는지.\n",
        "spec_rolloff = librosa.feature.spectral_rolloff(data, sr=sr)[0]\n",
        "rolloff_mean = np.mean(spec_rolloff)\n",
        "rolloff_var = np.var(spec_rolloff)\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "librosa.display.waveplot(data, sr=sr, alpha=0.5, color='b')\n",
        "plt.plot(t, preprocessing.minmax_scale(spec_rolloff), color='r') # 0-1사이로 맞춰 디스플레이\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jF5UqqfDhgt"
      },
      "source": [
        "# 음계와 관련한 부분을 시각화\n",
        "chroma_stft = librosa.feature.chroma_stft(data, sr=sr)\n",
        "chroma_stft_mean = np.mean(chroma_stft)\n",
        "chroma_stft_var = np.var(chroma_stft)\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "lplt.specshow(chroma_stft, sr=sr, x_axis='time', y_axis='chroma', cmap='coolwarm')\n",
        "plt.colorbar()\n",
        "plt.title(\"Chroma Features\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij-GGt5WP-4v"
      },
      "source": [
        "# 오디오 샘플에서 각 프레임에 대한 RMS를 계산하는 함수\n",
        "rms = librosa.feature.rms(data)\n",
        "rms_mean = np.mean(rms)\n",
        "rms_var = np.var(rms)\n",
        "\n",
        "spec_bw = librosa.feature.spectral_bandwidth(data, sr=sr)\n",
        "spectral_bandwidth_mean = np.mean(spec_bw)\n",
        "spectral_bandwidth_var = np.mean(spec_bw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auTi-IyUP83Q"
      },
      "source": [
        "# 음악 장르 분석, 음성 인식 등 다양한 분야에서 사용되는 특성 추출법 MFCC\n",
        "MFCCs = librosa.feature.mfcc(data, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mfcc=39)\n",
        "\n",
        "# display MFCCs\n",
        "plt.figure(figsize=(16,6))\n",
        "librosa.display.specshow(MFCCs, sr=sr, hop_length=hop_length)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"MFCC coefficients\")\n",
        "plt.colorbar()\n",
        "plt.title(\"MFCCs\")\n",
        "\n",
        "# show plots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR1JUNHwlXWq"
      },
      "source": [
        "# 데이터 셋을 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE3xzYGZtWIe"
      },
      "source": [
        "m3 = pd.read_csv('drive/MyDrive/kaggle/Data/features_3_sec.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5PVa1_6tq9W"
      },
      "source": [
        "m3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-DIKY215qXG"
      },
      "source": [
        "print(\"데이터(3초) 형태 :\",m3.shape)\n",
        "print(\"총 10 클래스의 장르들과 각 장르별 데이터 수 :\")\n",
        "m3['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-RXKkUGXXk7"
      },
      "source": [
        "# 각 mean column들의 히트맵 \n",
        "spike_cols = [col for col in m3.columns if 'mean' in col]\n",
        "corr = m3[spike_cols].corr()\n",
        "\n",
        "# 대각선 기준 윗면 삼각형 가리기\n",
        "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "\n",
        "# 사이즈 설정 + 팔레트\n",
        "f, ax = plt.subplots(figsize=(16, 11));\n",
        "cmap = sns.diverging_palette(150, 275, s=80, l=55, n=9)\n",
        "\n",
        "# 히트맵 그리기\n",
        "sns.heatmap(corr, cmap=cmap, vmax=.3, center=0, mask=mask,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n",
        "plt.title('Correlation Heatmap (only \"mean\" variables)', fontsize = 20)\n",
        "plt.xticks(fontsize = 10)\n",
        "plt.yticks(fontsize = 10);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t-tRFP6ZZkw"
      },
      "source": [
        "label_index = dict()\n",
        "index_label = dict()\n",
        "for i, x in enumerate(m3.label.unique()):\n",
        "    label_index[x] = i\n",
        "    index_label[i] = x\n",
        "print(index_label)\n",
        "m3.label = [label_index[l] for l in m3.label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UZBtiWgZdRu"
      },
      "source": [
        "features = m3.drop(['label','filename','length'],axis=1)\n",
        "target = m3['label'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHUmcgC8Zs1t"
      },
      "source": [
        "cols = features.columns\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "np_scaled = min_max_scaler.fit_transform(features)\n",
        "\n",
        "features = pd.DataFrame(np_scaled, columns = cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTs2-m9YlC1u"
      },
      "source": [
        "features # 정규화 완료"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LuaZqqKlM9A"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, test1, y_train, test2 = train_test_split(features, target, test_size=0.3, random_state=seed)\n",
        "print(X_train.shape, y_train.shape)\n",
        "X_val, X_test, y_val, y_test = train_test_split(test1, test2, test_size=0.2, random_state=seed)\n",
        "X_val.shape, X_test.shape, y_val.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlNzeBqbmKeJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.callbacks import EarlyStopping,LearningRateScheduler\n",
        "from keras import Sequential\n",
        "from keras.layers import *\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjzaAH-UlnyZ"
      },
      "source": [
        "# Deep Learning Model 만들기\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRMkXKm9mJxH"
      },
      "source": [
        "early_stopping= EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ajxf7qF-767"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics='accuracy')\n",
        "a = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=150, \n",
        "                     batch_size=batch_size, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lnyg5SSnS1Q"
      },
      "source": [
        "print(\"Max. Validation Accuracy\",max(a.history[\"val_accuracy\"]))\n",
        "pd.DataFrame(a.history).plot(figsize=(12,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQrvrm2Ejqi"
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjnYyOiGEqrn"
      },
      "source": [
        "\n",
        "model2.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics='accuracy')\n",
        "a2 = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=150, \n",
        "                     batch_size=batch_size, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr8jwKWpE5_2"
      },
      "source": [
        "print(\"Max. Validation Accuracy\",max(a2.history[\"val_accuracy\"]))\n",
        "pd.DataFrame(a2.history).plot(figsize=(12,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn7jPusxFNcj"
      },
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(256, activation='relu'))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(64, activation='relu'))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8awMIUw5FcqY"
      },
      "source": [
        "\n",
        "model3.compile(optimizer='sgd',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics='accuracy')\n",
        "a3 = model3.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, \n",
        "                     batch_size=batch_size, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nMu__KmGxco"
      },
      "source": [
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Dense(1024, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Dense(512, activation='relu'))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Dense(256, activation='relu'))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Dense(64, activation='relu'))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Dense(10, activation='softmax'))\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnUIgJJPG33K"
      },
      "source": [
        "model4.compile(optimizer='rmsprop',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics='accuracy')\n",
        "a4 = model4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, \n",
        "                     batch_size=batch_size, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsO64SSVIbTA"
      },
      "source": [
        "print(\"Max. Validation Accuracy\",max(a4.history[\"val_accuracy\"]))\n",
        "pd.DataFrame(a4.history).plot(figsize=(12,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRGUIIKDnUiR"
      },
      "source": [
        "test_loss, test_acc  = model4.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"The test Loss is :\",test_loss)\n",
        "print(\"\\nThe Best test Accuracy is :\",test_acc*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twu9zARZiRjS"
      },
      "source": [
        "def predict(model, X, y):\n",
        "    #X = X[np.newaxis,...]\n",
        "    prediction = model.predict(X)\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "    print(f\"Expected label:\")\n",
        "    print(f\"{y}, Predicted label: {predicted_index}\")\n",
        "predict(model4, X_test.head(), y_test.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tg9QTcmE9fA"
      },
      "source": [
        "spectrogram 이미지로 딥러닝 적용해보기 + 더 좋은 데이터셋 등 보완해야 할 점이 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeyRX9GcA3AU"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\n",
        "xgb.fit(X_train, y_train)\n",
        "preds = xgb.predict(X_val)\n",
        "print('Accuracy', 'XGB Classifier', ':', round(accuracy_score(y_val, preds), 5), '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}