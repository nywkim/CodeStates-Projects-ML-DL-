{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP82BQ0dc+w+UuEYCIoNVny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nywkim/project/blob/main/project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ6PpEAhzUQ1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sp = pd.read_csv('data_ind.csv', usecols=['acousticness', 'danceability', 'duration_ms', 'energy', 'liveness', 'loudness', 'speechiness',\n",
        "                'tempo', 'valence', 'song_title', 'artist', 'target', 'key'])\n",
        "sp.columns = ['Acousticness', 'Danceability', 'Duration (ms)', 'Energy', 'Chord',\n",
        "       'Liveness', 'Loudness', 'Speechiness', 'Tempo', 'Valence', 'target', 'Song Name', 'Artist']\n",
        "test = pd.read_csv('spotify_dataset.csv', usecols=['Acousticness', 'Danceability', 'Duration (ms)', 'Energy',\n",
        "       'Liveness', 'Loudness', 'Speechiness', 'Tempo', 'Valence', 'Song Name', 'Artist', 'Chord'])\n",
        "test['Chord'] = test.Chord.replace(['C', 'C#/Db', 'D', 'D#/Eb', 'E', 'F', 'F#/Gb', 'G', 'G#/Ab', 'A', 'A#/Bb', 'B'], [0,1,2,3,4,5,6,7,8,9,10,11])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SU2SOs6-s4i"
      },
      "source": [
        "sp.drop_duplicates(subset=None,inplace=True)\n",
        "spotify = sp.drop(columns=['target', 'Song Name', 'Artist'], axis=1)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(spotify.corr(),annot=True,cmap='summer')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXrHRctI4Eom"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "target = 'target'\n",
        "sp_t = sp[target].value_counts()\n",
        "px.pie(sp, values=sp_t, names=['liked','disliked'], title=\"Liked/Unliked Songs Distribution Pie Chart\", \n",
        "       color_discrete_sequence=[\"#1A466C\", \"#81292b\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urTgRIJRaypj"
      },
      "source": [
        "sp.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdaXbEBZc0jD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEp47llypp8K"
      },
      "source": [
        "sp_s = sp.sort_index(axis=1)\n",
        "test_s = test.sort_index(axis=1)\n",
        "\n",
        "sp = sp_s.drop(columns=['Song Name', 'Artist', 'target'], axis=1)\n",
        "X_test = test_s\n",
        "sp_ = sp_s[['target','Song Name', 'Artist']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFj_uiRnf2CI"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def vif_show(X_vif):\n",
        "    vif = pd.DataFrame()\n",
        "    vif['Features'] = X_vif.columns\n",
        "    vif['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
        "    vif['VIF'] = round(vif['VIF'], 2)\n",
        "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "    print(vif)\n",
        "    print()\n",
        "    if(vif.iloc[0,1] > 5.0 ):\n",
        "        col = vif.iloc[0,0]\n",
        "        X_vif.drop([vif.iloc[0,0]],axis =1, inplace = True)\n",
        "        print(\"After removing \\\"\"+ col + \"\\\" from datafame\")\n",
        "        vif_show(X_vif)\n",
        "\n",
        "vif_show(sp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVfw2B--1-yr"
      },
      "source": [
        "sp = pd.concat([sp,sp_],axis = 1)\n",
        "train, val = train_test_split(sp, test_size=0.2, random_state=17)\n",
        "features = sp.drop(columns=[target]).columns\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQJ4FBJLCtqu"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree, ensemble\n",
        "from xgboost import XGBClassifier\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "import xgboost as xgboost\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTG_D_rMopoI"
      },
      "source": [
        "obj=list(np.where(X_train.dtypes == np.object)[0])\n",
        "model=CatBoostClassifier()\n",
        "model.fit(X_train,y_train,cat_features=obj)\n",
        "y_pred = model.predict(X_val)\n",
        "print(classification_report(y_val,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqLX8LyA8mfs"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "fig, ax = plt.subplots()\n",
        "pcm = plot_confusion_matrix(model, X_val, y_val,\n",
        "                            cmap=plt.cm.Blues,\n",
        "                            ax=ax,values_format = '');\n",
        "plt.title(f'Confusion matrix, n = {len(y_val)}', fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqnarZg57cK"
      },
      "source": [
        "y_pred_proba = model.predict_proba(X_val)[:, -1]\n",
        "print('AUC score: ', roc_auc_score(y_val, y_pred_proba))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1nqwh0w57Wz"
      },
      "source": [
        "a = pd.DataFrame(data=[y_pred,y_pred_proba]).T\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU5Q-KCu8Xm1"
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "plt.scatter(fpr, tpr, color='blue')\n",
        "plt.plot(fpr, tpr, color='green')\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7EamlL2UEuu"
      },
      "source": [
        "imp_df = pd.DataFrame({\n",
        "    \"ColumnName\": X_train.columns,\n",
        "    \"Imp\": model.feature_importances_})\n",
        "imp_df.sort_values(by=\"Imp\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PX6Z8vhiT-S"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols = ['Song Name', 'Artist']\n",
        "sp[cols] = sp[cols].apply(LabelEncoder().fit_transform)\n",
        "\n",
        "train, val = train_test_split(sp, test_size=0.2, random_state=17)\n",
        "features = sp.drop(columns=[target]).columns\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NgysUBhS8MC"
      },
      "source": [
        "\n",
        "! pip install category_encoders\n",
        "from category_encoders import OrdinalEncoder, TargetEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV, validation_curve\n",
        "\n",
        "X_train = X_train.drop(['Song Name'], axis=1)\n",
        "X_val = X_val.drop(['Song Name'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrD2CFOzZTVG"
      },
      "source": [
        "\n",
        "reg = LogisticRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "\n",
        "y_reg = reg.predict(X_val)\n",
        "print(confusion_matrix(y_val,y_reg))\n",
        "print(classification_report(y_val, y_reg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHpsrfCQnog9"
      },
      "source": [
        "rf = ensemble.RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_rf = rf.predict(X_val)\n",
        "print(confusion_matrix(y_val,y_rf))\n",
        "print(classification_report(y_val, y_rf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLgoBwKHluM2"
      },
      "source": [
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train,y_train)\n",
        "y_xgb = xgb.predict(X_val)\n",
        "print(confusion_matrix(y_val,y_xgb))\n",
        "print(classification_report(y_val, y_xgb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Fwx7E7mu_O"
      },
      "source": [
        "modelX = XGBClassifier(\n",
        "    n_estimators=1000,  # <= 1000 트리로 설정했지만, early stopping 에 따라 조절됩니다.\n",
        "    max_depth=7,        # default=3, high cardinality 특성을 위해 기본보다 높여 보았습니다.\n",
        "    learning_rate=0.2,\n",
        "#     scale_pos_weight=ratio, # imbalance 데이터 일 경우 비율을 적용합니다.\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "eval_set = [(X_train, y_train), \n",
        "            (X_val, y_val)]\n",
        "\n",
        "modelX.fit(X_train, y_train, \n",
        "          eval_set=eval_set,\n",
        "          eval_metric='error', # #(wrong cases)/#(all cases)\n",
        "          early_stopping_rounds=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVZxyAyVnCKD"
      },
      "source": [
        "results = modelX.evals_result()\n",
        "train_error = results['validation_0']['error']\n",
        "val_error = results['validation_1']['error']\n",
        "\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.legend();\n",
        "y_xgb1 = modelX.predict(X_val)\n",
        "print(confusion_matrix(y_val,y_xgb1))\n",
        "\n",
        "print(classification_report(y_val, modelX.predict(X_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlSnQ-efnV9o"
      },
      "source": [
        "# xgboost.plot_importance(modelX)\n",
        "imp_df1 = pd.DataFrame({\n",
        "    \"ColumnName\": X_train.columns,\n",
        "    \"Imp\": modelX.feature_importances_})\n",
        "imp_df1.sort_values(by=\"Imp\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIhT6GHTosPv"
      },
      "source": [
        "X_test = test_s[features]\n",
        "\n",
        "y_test = model.predict(X_test)\n",
        "y_test_proba = model.predict_proba(X_test)[:, -1]\n",
        "X_test['Maybe You Like...(%)'] = y_test_proba * 100\n",
        "X_test = X_test.sort_values('Maybe You Like...(%)', ascending=False)\n",
        "X_test = X_test.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqCEquyqtMST"
      },
      "source": [
        "features_t = ['index', 'Artist', 'Song Name', 'Maybe You Like...(%)']\n",
        "recommends = X_test[features_t]\n",
        "recommends = recommends.drop('index', axis=1)\n",
        "recommends.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}